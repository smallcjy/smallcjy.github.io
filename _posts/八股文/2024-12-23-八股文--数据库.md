---
title: 数据库知识合集
date: 2024-08-02 10:48:31
tags: [数据库]
---

## 基础篇+杂记篇

### Mysql select 语句执行流程图

![alt text](assets/img/2024-12-23-八股文--数据库/image-7.png)

### mysql 有几种存储引擎？

常见的存储引擎好像有：InnoBD，MyISAM，Memory等。

### 什么是回表

在使用非聚簇索引进行查询时，通过二级索引查询到主键后需要重新根据主键索引查询到完整数据，这个重新回到数据库表查询的过程就是回表，

### Mysql优化总结 （好文）

当系统的性能瓶颈来到数据库层面，需要优化Mysql，可以按照下面的思路来进行：

总的优化思路分为三个：软件、硬件、架构

**软件层面**

1. mysql版本升级

mysql版本的升级通常伴随着官方的性能优化，例如mysql5.2版本到8.0版本性能提升了两倍；同时会提供新的提高读写性能的方法，例如新版本的mysql支持**索引拆分**；

2. 建立合适的索引

当读性能不足时，可以考虑建立合适的索引。可以在区分度比较高的列上建立索引，比如在唯一列上建立主键索引，在不太可能重复的列上建立二级索引。

如果索引的大小过大，可以考虑使用前缀索引，取字段的前几个字符建立索引，提高io性能；

3. sql语句优化

优化点：

- sql语句有没有走索引查询，还是全表扫描？（索引失效）
- 回表次数太多？
- 单行查询的数据量太大，IO性能太低

这里讲下索引失效。查询条件中包含索引项，但是实际查询走的全表扫描。索引失效发生的原因包括下面几点：

1. **模糊匹配**，`like %aa`会导致索引失效；
2. in 比较大的数据时，可能会导致索引失效；
3. 在条件查询时，**使用不等于条件**，**范围查询时包含OR条件并且对象存在未建立索引的情况**，这两种情况会直接导致索引失效

4. 回表次数

调整索引结构，尝试实现索引覆盖或者使用索引下沉去优化

5. 数据库优化

   1. 数据库设计 / 表结构优化

   首先是字段，主键通常设计为递增数字，一方面插入新记录会插入在最后，防止索引重建；另一方面比较大小方便；然后是表结构，通常需要遵循三大规范，但是遵循三大规范的代价是会使用大量的join，导致性能下降。这时可以允许一些数据冗余，减少join的使用。

   三大规范：

   - 1NF：原子性，每个字段的值不可继续拆分
   - 2NF：唯一性，表内每行数据必须描述同一业务属性的数据
   - 3NF：独立性，表中的非主键字段之间不能存在依赖性（使用join的原因，若存在依赖则需新建张表）

   2. 分库分表

## 存储结构篇

### innoDB 是怎么存储一个行数据的？

在讲这个问题之前，我们先来了解下MySQL的数据是保存在哪个文件的。当我们创建一个database后，会在var/lib/mysql目录下创建一个以数据库为名的目录。保存表结构和表数据的文件都会存放在这个目录里。该目录下有三种类型的文件：
- db.opt: 存储当前数据库的默认字符集和字符校验的规则；
- t_order.frm: 存储表结构的文件（元数据，表结构定义）
- t_order.ibd: 存储表数据的文件

存储数据的文件，你知道这个文件的结构是吗？表空间由段（segment）、区（extent）、页（page）、行（row）组成。

![alt text](assets/img/2024-12-23-八股文--数据库/image-8.png)

- 行：数据库表中的记录都是按行（row）进行存放的，每行记录根据不同的行格式，有不同的存储结构。 后面我们详细介绍 InnoDB 存储引擎的行格式，也是本文重点介绍的内容。
- 页：InnoDB 的数据是按「页」为单位来读写的，默认每个页的大小为 16KB。页是innodb的最小磁盘资源管理单元，也是磁盘和内存之间传输的最小单位。
- 区：在表中数据量大的时候，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区（extent）为单位分配。每个区的大小为 1MB，对于 16KB 的页来说，连续的 64 个页会被划为一个区，这样就使得链表中相邻的页的物理位置也相邻，就能使用**顺序 I/O** 了。
- 段：表空间是由各个段（segment）组成的，段是由多个区（extent）组成的。段一般分为数据段、索引段和回滚段等。
    - 索引段：存放 B + 树的非叶子节点的区的集合； 
    - 数据段：存放 B + 树的叶子节点的区的集合； 
    - 回滚段：存放的是回滚数据的区的集合， MVCC 利用了回滚段实现了多版本查询数据。

### **InnoDB 的行格式**
我们知道行是存储记录的，行格式就是存储记录的格式。InnoDB提供了四种行格式：Redundant、Compact、Dynamic和Compressed。

- 重点介绍Compact行格式，这是InnoDB的默认行格式

![alt text](assets/img/2024-12-23-八股文--数据库/image-9.png)

记录 = 记录的额外信息 + 记录的真实信息

**记录的额外信息**： 变长字段长度列表、NULL 值列表、记录头信息
- 变长字段长度：像varchar这种字段的长度不是固定的，而是由用户定义的可变长的，需要记录对应的真实数据的长度。

变长字段的真实数据占用的字节数会按照列的顺序逆序存放，**为什么呢？**，记录头信息中指向下一个记录的指针，指向的是系啊一条记录的记录头信息和真实数据之间的位置。变长字段长度列表和NULL值列表逆序排放可以提高访问效率，可以使得位置靠前的记录的真实数据和数据对应的 字段长度信息可以同时存在在一个CPU Cache Line，提高CPU cache的命中率。

- NULL值列表：如果存在允许 NULL 值的列，则每个列对应一个二进制位（bit），二进制位按照列的顺序逆序排列。 二进制位的值为1时，代表该列的值为NULL。 二进制位的值为0时，代表该列的值不为NULL。 另外，NULL 值列表必须用整数个字节的位表示（1字节8位），如果使用的二进制位个数不足整数个字节，则在字节的高位补 0。

注意：值为NULL的列是不会储存在真实数据中的，只会在NULL值列表中的相应位置置为1。

- 记录头信息：
- delete_mask ：标识此条数据是否被删除。从这里可以知道，我们执行 detele 删除记录的时候，并不会真正的删除记录，只是将这个记录的 delete_mask 标记为 1。 
- next_record：下一条记录的位置。从这里可以知道，记录与记录之间是通过链表组织的。在前面我也提到了，指向的是下一条记录的「记录头信息」和「真实数据」之间的位置，这样的好处是向左读就是记录头信息，向右读就是真实数据，比较方便。 
- record_type：表示当前记录的类型，0表示普通记录，1表示B+树非叶子节点记录，2表示最小记录，3表示最大记录

**记录的真实数据**
![alt text](assets/img/2024-12-23-八股文--数据库/image-10.png)

就是记录各列的值，重点是有三个字段：row_id、trx_id、roll_pointer

- row_id(6个字节)：如果我们建表的时候指定了主键或者唯一约束列，那么就没有 row_id 隐藏字段了。如果既没有指定主键，又没有唯一约束，那么 InnoDB 就会为记录添加 row_id 隐藏字段。row_id不是必需的，占用 6 个字节。
- trx_id(6个字节): 事务id，表示这个数据是由哪个事务生成的。 trx_id是必需的，占用 6 个字节。
- roll_pointer(7个字节)：回滚指针，表示这个数据的回滚指针，即记录上个版本的指针。roll_pointer是必需的，占用 7 个字节。

### 如何计算varchar（n）的n最大值？

- 单字段

n的最大值不能超过65535，使用65535 - NULL值列表占用字节数 - 变长字段长度列表占用字节数(变长字段占有字节数小于255占用1个字节，大于255占用2个字节) = 可以使用的最大n

注意这是在ascill的情况下，一个字符占有一个字节；在utf8的情况下，一个字符占有3个字节。所以在utf8的情况下，n的最大值就是可以使用最大n/3

- 多字段

如果有多个字段，要保证所有字段的长度之和小于等于可以使用的最大字节数。

### 行溢出如何处理

当某列值类型为text长文本类型时，大概率会发生行溢出，即一行里面没办法存储所有的数据。前面我们知道有页这个结构，页有个类型叫做溢出页，当一行的数据无法存储在一个页里面时，就会存储在溢出页里面。然后在真实数据内使用20个字节存贮溢出页的地址。

## 事务篇

### MVCC 是什么？&& innoDB 事务的隔离级别

MVCC叫多版本并发控制，用来实现可恢复读的隔离级别的。

首先来深挖这句话。

什么是隔离？隔离是事务的四大特性之一，其他的特性分别是ACID，原子性，一致性，隔离性，持久性。

- 原子性：一个事务中的所有操作，要么全部完成，要么全部不完成。如果事务执行过程中发生错误，就要触发回滚到事务开始前的状态。通过**undo日志**实现
- 一致性：事务操作前和操作后数据满足完成性约束。换句话来说，就是数据要保持完整。这个特性的实现是依靠其他三个特性的。
- 隔离性：数据库允许并发事务，同时多个并发事务的交叉执行不能导致数据的不一致。隔离性的实现是比较困难的，下文会介绍。通过MVCC实现或者锁机制
- 持久性：事务一旦提交，对数据的改变是永久性的。通过redo日志。

下面来详细讲解隔离性的实现。

首先实现隔离性会遇到即可困难，这个困难是伴随并发事务的出现必然会出现的。

- 脏读：一个事务读到另一个事务的未提交的修改的数据。

![alt text](assets/img/2024-12-23-八股文--数据库/image-11.png)

- 不可重复读：一个事务两次读取同一个数据的内容不一样。

![alt text](assets/img/2024-12-23-八股文--数据库/image-12.png)

- 幻读：一个事务内两次查询到的符合查询条件的记录数量不一致。

![alt text](assets/img/2024-12-23-八股文--数据库/image-13.png)

通过解决上面的问题中的几个，划分出多个隔离级别，

- 什么也没解决：读未提交级别；
- 解决脏读：读提交级别；
- 解决脏读和不可重复读：可重复读级别；
- 解决脏读、不可重复读和幻读：串行化级别。

等于于读提交级别和可重复读级别的实现就是Read View来实现的，它们的区别就是创建读快照的时机不同而已。读提交级别是在每个语句执行前都会重新生成一个读快照。可重复读级别是在事务开始的时候生成一个读快照。

**Read View在MVCC中式如何工作的**

Read View到底是什么？

Read View的组成中有四个重要的字段：creator_trx_id, m_ids, min_trx_id, max_trx_id
- creator_trx_id：创建者事务ID，即创建这个Read View的事务ID；
- m_ids：创建Read View时，当前数据库中**活跃但未提交**的事务id列表；
- min_trx_id：创建Read View时，最小的活跃事务ID；
- max_trx_id：创建Read View时，应当给下一个事务的id值。

![alt text](assets/img/2024-12-23-八股文--数据库/image-15.png)

还记得我们在之前的行结构的讲解中讲到记录真实数据中的隐藏字段吗？就是trx_id 和 rolled_pointer。这里可以讲讲这两个字段的作用了。

![alt text](assets/img/2024-12-23-八股文--数据库/image-14.png)

- trx_id：当一个事务对某条聚簇索引记录进行改动时，就会把该事务id记录在trx_id字段中。
- roll_pointer：每次对某条聚簇记录进行改动时，都会把旧版本的记录写入到undo日志中。然后这个隐藏列是个指针，指向每一个旧版本记录，于是就可以通过它找到修改前的记录。

**非常重要的地方来叻！**

一个事务去访问记录的时候，除了**自己的更新记录总是可见之外**，还有这几种情况： 
- 如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务**可见**。 
- 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务**不可见**。 
- 如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中： 
  - 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 
  - 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 

**这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。**

**注意：不可见只是在查询的时候会取查找旧版本的数据，但是你修改就直接修改了。**

**可重复读是如何工作的？**
可重复读隔离级别是在启动事务时生成一个Read View，然后整个事务期间都在用这个Read View。

![alt text](assets/img/2024-12-23-八股文--数据库/image-16.png)

举个例子：

- 事务 B 读取小林的账户余额记录，读到余额是 100 万； 
- 事务 A 将小林的账户余额记录修改成 200 万，并没有提交事务； 
- 事务 B 读取小林的账户余额记录，读到余额还是 100 万； 
- 事务 A 提交事务； 
- 事务 B 读取小林的账户余额记录，读到余额依然还是 100 万；

接下来，跟大家具体分析下。 

事务 B 第一次读小林的账户余额记录，在找到记录后，它会先看这条记录的 trx_id，此时发现 trx_id 为 50，比事务 B 的 Read View 中的 min_trx_id 值（51）还小，这意味着修改这条记录的事务早就在事务 B 启动前提交过了，所以该版本的记录对事务 B 可见的，也就是事务 B 可以获取到这条记录。 

接着，事务 A 通过 update 语句将这条记录修改了（还未提交事务），将小林的余额改成 200 万，这时 MySQL 会记录相应的 undo log，并以链表的方式串联起来，形成版本链，如下图：

![alt text](assets/img/2024-12-23-八股文--数据库/image-17.png)

你可以在上图的「记录的字段」看到，由于事务 A 修改了该记录，以前的记录就变成旧版本记录了，于是最新记录和旧版本记录通过链表的方式串起来，而且最新记录的 trx_id 是事务 A 的事务 id（trx_id = 51）。 

然后事务 B 第二次去读取该记录，发现这条记录的 trx_id 值为 51，在事务 B 的 Read View 的 min_trx_id 和 max_trx_id 之间，则需要判断 trx_id 值是否在 m_ids 范围内，判断的结果是在的，那么说明这条记录是被还未提交的事务修改的，这时事务 B 并不会读取这个版本的记录。

而是沿着 undo log 链条往下找旧版本的记录，直到找到 trx_id 「小于」事务 B 的 Read View 中的 min_trx_id 值的第一条记录，所以事务 B 能读取到的是 trx_id 为 50 的记录，也就是小林余额是 100 万的这条记录。 

最后，当事物 A 提交事务后，由于隔离级别时「可重复读」，所以事务 B 再次读取记录时，还是基于启动事务时创建的 Read View 来判断当前版本的记录是否可见。所以，即使事物 A 将小林余额修改为 200 万并提交了事务， 事务 B 第三次读取记录时，读到的记录都是小林余额是 100 万的这条记录。 

就是通过这样的方式实现了，「可重复读」隔离级别下在事务期间读到的记录都是事务启动前的记录。

**读提交是如何工作的？**

工作流程和可重复读基本一致，区别的地方在于都快照创建的时机不同，读提交创建的时机是每次读取数据时，都会生成一个读快照。

以上便是MVCC的工作流程了。

那么幻读呢？

对于快照读(即普通的select语句)，通过MVCC机制避免；对于当前读语句，是通过next-key lock(记录锁+间隙锁)的方式解决幻读的对于锁机制的讲述，在下文进行。

## 锁篇

### Mysql有哪些锁？

- 全局锁

- 表级锁

  - 表锁
  - 元数据锁(MDL)
  - 意向锁
  - AUTO-INC锁

- 行级锁

  - Record 锁

  - Gap 锁

  - Next-key 锁

  - 插入意向锁（防止被饿死）


## 索引篇

### 索引有哪些

inoodb的索引的类型可以从四个角度取分类：数据结构、物理储存、字段特性、字段个数

以下是MySQL索引分类的表格形式整理：

| 分类维度         | 索引类型             | 说明                                                     |
| ---------------- | -------------------- | -------------------------------------------------------- |
| **数据结构**     | B+树索引             | 最常用的索引类型，支持范围查询和排序                     |
|                  | 哈希索引             | 基于哈希表实现，仅支持等值查询，Memory引擎默认使用       |
|                  | Full-text索引        | 全文检索索引，用于文本内容的搜索                         |
|                  | R-Tree索引           | 空间索引，用于地理空间数据类型                           |
| **物理存储方式** | 聚簇索引(主键索引)   | InnoDB中数据按主键物理排序存储，叶子节点存储完整数据记录 |
|                  | 非聚簇索引(辅助索引) | 叶子节点存储主键值，需要回表查询                         |
| **字段特性**     | 主键索引             | 特殊的唯一索引，不允许NULL值，表只能有一个               |
|                  | 唯一索引             | 索引列值必须唯一，但允许NULL值                           |
|                  | 普通索引             | 基本的索引类型，无唯一性约束                             |
|                  | 前缀索引             | 对字符类型字段前N个字符建立的索引，可节省空间            |
| **字段个数**     | 单列索引             | 只包含单个字段的索引                                     |
|                  | 联合索引(复合索引)   | 包含多个字段的索引，遵循最左前缀原则                     |

注意：联合索引的key值是多段的，按照最左匹配的原则。所以查询需要遵循最左匹配原则。‘

### 聚簇索引和非聚簇索引有什么区别

**聚簇索引**：也成为主键索引，在主键上建立索引，叶子节点上储存着完整的行记录；叶子节点之间通过双向链表连接起来，方便范围查询；

**非聚簇索引**：也称为二级索引，在非主键上的唯一项上建立索引，叶子节点上储存主键；**通常需要回表**查询到所需的数据 

### 什么是索引的最左前缀匹配原则

使用联合索引进行查询时，查询条件要从联合索引的最左侧开始进行匹配。联合索引包含多个列，查询条件必须包含第一个列的条件，然后是第二个列等等。

### 什么是回表

在使用非聚簇索引进行查询时，通过二级索引查询到主键后需要重新根据主键索引查询到完整数据，这个重新回到数据库表查询的过程就是回表。

### 什么是索引下推 / index condition pushdown ICP

通过二级索引查到主键id后回表完再进行where条件过滤 **改为** 二级索引查到的数据后直接where过滤一遍再进行回表，减少回表的次数。

### 什么是索引失效

查询条件中包含索引项，但是实际查询走的全表扫描。索引失效发生的原因包括下面几点：

1. **模糊匹配**，`like %aa`会导致索引失效；

2. 使用联合索引，但是查询却不符合最左匹配原则；

3. ###### 查询条件的索引中包含**运算**和函数；

4. in 比较大的数据时，可能会导致索引失效；

5. 在条件查询时，**使用不等于条件**，**范围查询时包含OR条件并且对象存在未建立索引的情况**，这两种情况会直接导致索引失效

6. 随意的字段使用，导致包含类型的隐式转换；

7. order by 后面不是主键或者覆盖索引；

### 索引优化方法

- 前缀索引优化
- 覆盖索引优化
- 主键索引最好是自增的
- 防止索引失效
- 索引最好设置为NOT NULL

### 为什么要使用B+树作为索引数据结构？

- 查询效率高
- IO次数少
- 插入删除对于B+树的结构变化小
- B+树的叶子节点是有序的，可以做范围查询

**Mysql中的B+tree**

![alt text](assets/img/2024-12-23-八股文--数据库/image-18.png)

### Mysql 中的B+Tree的数据页结构是怎样的

B+树中间节点和叶子结点的结构类似，都是数据页结构。B+树的数据页结构是这样的：

|               File Header 文件头                |
| :---------------------------------------------: |
|              **Page Header 页头**               |
| Infimun Record + Supermun Record 最小和最大记录 |
|   User Records 用户记录（实际数据存储的地方）   |
|               Free Space 空闲空间               |
|              Page Directory 页目录              |
|               File Tailer 文件尾                |

**File Header**：B+树中每层都是一个双向链表，其实现就是靠File Header。File Header包含FIL_PAGE_PRE FIL_PAGE_NEXT FIL_TYPE（区分索引页、数据页、Undo日志页）。

**Infimun Record + Supermun Record：** 两个虚拟的记录，用来确定页的区间，是左开右开区间；

**Page Directory 页目录 重点**

页目录的作用是在页内通过二分查找快速找到目标记录；User Records中的记录是按分组的形式组织的，每个分组对应目录内的一个slot，slot指向分组内的最大记录；页目录实际上是个slot数组，通过对slot指向的最大记录进行二分查找，可以快速定位到目标记录位于那个分组，然后在分组内线性查找即可。 

**User Records**

用户记录按照分组的形式组织，分为首分组，中间分组，末尾分组。索引记录：key + 指向下一页的指针；数据记录：key + record

## 日志篇

### MySQL日志：undo log、redo log、binlog

- undo log: Innodb存储引擎生成的日志，用于实现事务中的原子性，主要用于事务回滚和MVCC
- redo log：Innodb存储引擎生成的日志，实现事务中的持久性，主要用于掉电等实例崩溃后的恢复
- binlog：Server层生成的日志，主要用于数据备份和主从复制
### undolog
回滚流程：

![alt text](assets/img/2024-12-23-八股文--数据库/image-19.png)

- 支持事务回滚，实现事务的原子特性
- 是MVCC实现的关键因素

Undo页面：储存事务回滚日志undolog的页面

### redolog

**WAL技术 Write-Ahead Logging**

MySQL的写操作并不是立即马上写到磁盘中，而是先写日志，然后在合适的时间再写到磁盘上。

relog：记录此次事务修改后的数据状态，记录的是更新之后的值

reedo流程：

![alt text](assets/img/2024-12-23-八股文--数据库/image-20.png)

- 使用redolog实现事务的持久性特性
- 将写操作从随机写变成了顺序写

#### relog什么时候刷盘

缓存在 redo log buffer 里的 redo log 还是在内存中，它什么时候刷新到磁盘？ 

主要有下面几个时机： 
- MySQL 正常关闭时； 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘； 
- InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。
- 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下图说明了参数不同时的各自刷盘策略）。

![alt text](assets/img/2024-12-23-八股文--数据库/image-21.png)

### binlog
前两个日志是InnoDB引擎特有的，而binlog是MySQL的Server层实现的。

binlog文件记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作，比如select、show等。

**读到这里可能会好奇，既然有了 redo log，为什么还要有 binlog 呢？redolog和binlog的区别是什么？**

这个问题和Mysql的时间线有关。最开始 MySQL 里并没有 InnoDB 引擎，MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。 而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用 redo log 来实现 crash-safe 能力。

区别主要有四个：

![alt text](assets/img/2024-12-23-八股文--数据库/image-22.png)

![alt text](assets/img/2024-12-23-八股文--数据库/image-23.png)


#### **Binlog还有个非常重要的作用，就是实现MYSQL的主从复制**

![alt text](assets/img/2024-12-23-八股文--数据库/image-24.png)

MySQL 集群的主从复制过程梳理成 3 个阶段： 
- 写入 Binlog：主库写 binlog 日志，提交事务，并更新本地存储数据。 
- 同步 Binlog：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。 
-  回放 Binlog：回放 binlog，并更新存储引擎中的数据。

**同样有何时刷盘问题？**

当事务开始时，将上一个事务的binlog提交到binlog cache中，当事务完成时在将binlog cache刷盘。

频繁的刷盘会导致io过快，myssql提供一个参数来控制binlog的刷盘频率：sync_binlog / 这不是跟redis的appendfsync参数一毛一样吗？其实binlog的设计和redis的aof日志的设计上有异曲同工之妙。

## 集群篇

### 两阶段提交

两阶段提交的阐述我讲按照why+what+how两个部分进行。

**为什么需要两阶段提交**

我们知道，在事务提交后，redolog和binlog都要持久化都磁盘中，这是两个独立的逻辑，于是就有可能出现半成功的情况。redolog的作用是crash-save，binlog的作用是主从复制。如果这两份日志的结果出现不同，那么如果在发生crash后，就会导致恢复的数据和其他数据库不一样，从而发生数据丢失。那么如何解决这个问题呢？这里就提到了两阶段提交。

**什么是两阶段提交**

两阶段提交是一种分布式事务一致性的协议，可以保证多个逻辑操作要不全部成功，要不全部失败，不会出现半成功的情况。两阶段提交是指把事务的提交工作分成prepare阶段和commit阶段。

**两阶段提交的过程是怎样的呢**

binlog和redolog的入盘过程有XA事务负责保证其成功的一致性。事务的提交过程有两个阶段，把redolog的写入拆分成两个阶段，prepare和commit，中间再穿插写入binlog：

- prepare阶段：将XID写入到redolog，同时将redolog对应的事务状态设置为prepare，然后将redolog持久化到磁盘中；
- commit阶段：将XID写入到binlog，然后将binlog持久化到磁盘中，接着调用引擎的提交事务接口，将redolog状态设置为commit，此时该状态并不需要持久化到磁盘中，只需要write到文件系统的page cache中，因为只要binlog写磁盘成功，就算redolog的状态是prepare也没有关系，事务一样被认定为执行成功。

下面来看下不同情况下系统崩溃，两阶段提交是如何保证一致性的。

1. prepare阶段结束，commit还没开始时系统崩溃，此时redolog已经写入磁盘，但binlog没有写入磁盘。
2. prepare阶段结束，commit进行一半系统崩溃。

系统重启后，扫描redolog文件，碰到prepare标识的redolog，就拿着这个XID去查看binlog是否存在这个XID：
- 如果不存在，说明redolog完成刷盘，但binlog没有刷盘，则说明事务提交失败，需要回滚在XA事务。对应情况1；
- 如果存在，说明全都完成刷盘，对应情况2。调用提交事务接口，完成事务提交工作
